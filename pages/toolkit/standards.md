---
title: Open Data Standards
parent: Toolkit
---

Open Data is spreading across the globe, and each country has its own open data programme. However when we look through the released data, we can conclude that the this is a happening without well documented standards, and the result is inconsistent meta data, no uniform approval process, non-uniform normalisaton process, conflicting terms of use.

And this is not just limited to different countries or organisations. Open data is hard to compare even across teams located in the same building.

## What are standards with respect to open data? And why do we need them?

By standards here we mean something widely accepted, agreed upon, or established means of determining what something should be.

This is to allow datasets from different agencies to be easily comparable, joined into something bigger, to support wider research, knowledge exchange, app scalability and in general to make it easy for the value addeed resellers.
n
Once defined, the process will help ease the whole ritual acssociated with releasing a dataset.

This also aligns with the concept of frictionless data that was introduced by Open knowledge foundation.

Some examples of uniformity in datasets are:
- Similar data and time format across all datasets
- Having minimum required fields 
- Similar dataset across different agencies should have similar structure and fields

This needs to be taken up as an elaborate api design initiative that should involve representative from all government agencies. A collaborative effort done once can save a lot of time in the hindsight.

A few references for standards are:
- [Open Council Data Standard Australia](standards.opencouncildata.org)
- [W3C open data standards](https://www.w3.org/TR/dwbp)
- [Open Data Handbook Standards](opendatahandbook.org/resources/#standards)
- [Frictionless Data](https://okfn.org/projects/frictionless-data)